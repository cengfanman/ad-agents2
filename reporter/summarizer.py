"""OpenAI å ±å‘Šæ‘˜è¦ç”Ÿæˆå™¨"""
import os
from typing import Dict, Any, List
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage
from .templates import SYSTEM_PROMPT, USER_PROMPT_TEMPLATE


def generate_summary_report(strategy: Dict[str, Any], tools_executed: List[str]) -> str:
    """
    ä½¿ç”¨ OpenAI ç”Ÿæˆç°¡æ½”çš„å ±å‘Šæ‘˜è¦

    Args:
        strategy: ç­–ç•¥çµæœ
        tools_executed: åŸ·è¡Œçš„å·¥å…·åˆ—è¡¨

    Returns:
        str: Markdown æ ¼å¼çš„å ±å‘Š
    """
    # æª¢æŸ¥ API Key
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return _generate_fallback_report(strategy, tools_executed)

    try:
        # åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯
        model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
        llm = ChatOpenAI(
            model=model,
            temperature=0.3,
            max_tokens=500
        )

        # æº–å‚™ prompt è³‡æ–™
        tools_text = "\n".join([f"â€¢ {tool}" for tool in tools_executed])
        actions_text = _format_actions(strategy.get("actions", []))

        user_prompt = USER_PROMPT_TEMPLATE.format(
            primary_hypothesis=strategy.get("primary_hypothesis", "æœªçŸ¥"),
            confidence=strategy.get("confidence", 0),
            tools_executed=tools_text,
            actions=actions_text
        )

        # å»ºç«‹è¨Šæ¯
        messages = [
            SystemMessage(content=SYSTEM_PROMPT),
            HumanMessage(content=user_prompt)
        ]

        # èª¿ç”¨ OpenAI
        response = llm.invoke(messages)
        return response.content

    except Exception as e:
        print(f"âš ï¸  OpenAI å ±å‘Šç”Ÿæˆå¤±æ•—ï¼š{str(e)}")
        return _generate_fallback_report(strategy, tools_executed)


def _format_actions(actions: List[Dict[str, Any]]) -> str:
    """æ ¼å¼åŒ–è¡Œå‹•å»ºè­°ç‚ºæ–‡å­—"""
    if not actions:
        return "ç„¡å…·é«”è¡Œå‹•å»ºè­°"

    formatted = []
    for i, action in enumerate(actions, 1):
        text = f"{i}. {action.get('description', '')}"
        if action.get('impact'):
            text += f"\n   å½±éŸ¿ï¼š{action.get('impact')}"
        if action.get('kpi'):
            text += f"\n   KPIï¼š{action.get('kpi')}"
        formatted.append(text)

    return "\n\n".join(formatted)


def _generate_fallback_report(strategy: Dict[str, Any], tools_executed: List[str]) -> str:
    """
    ç”Ÿæˆæœ¬åœ°å‚™æ´å ±å‘Šï¼ˆç•¶ OpenAI ä¸å¯ç”¨æ™‚ï¼‰

    Args:
        strategy: ç­–ç•¥çµæœ
        tools_executed: åŸ·è¡Œçš„å·¥å…·åˆ—è¡¨

    Returns:
        str: Markdown æ ¼å¼çš„æœ¬åœ°å ±å‘Š
    """
    primary = strategy.get("primary_hypothesis", "æœªçŸ¥å•é¡Œ")
    confidence = strategy.get("confidence", 0)
    actions = strategy.get("actions", [])

    report = f"""# ğŸ“Š Amazon å»£å‘Šè¨ºæ–·å ±å‘Š

## ğŸ¯ è¨ºæ–·çµè«–
**{primary}**ï¼ˆç½®ä¿¡åº¦ï¼š{confidence:.1%}ï¼‰

## ğŸš€ å»ºè­°è¡Œå‹•

"""

    # æ·»åŠ å‰ä¸‰å€‹è¡Œå‹•å»ºè­°
    for i, action in enumerate(actions[:3], 1):
        report += f"""### {i}. {action.get('description', '')}
- **é æœŸå½±éŸ¿**ï¼š{action.get('impact', 'æå‡å»£å‘Šæ•ˆæœ')}
- **é¢¨éšªè©•ä¼°**ï¼š{action.get('risk', 'éœ€è¦æŒçºŒç›£æ§')}
- **é—œéµæŒ‡æ¨™**ï¼š{action.get('kpi', 'å¾…ç¢ºèª')}

"""

    report += """## â° åŸ·è¡Œæ™‚ç¨‹
- **T+48å°æ™‚**ï¼šæª¢æŸ¥åˆæ­¥æ•ˆæœå’ŒæŒ‡æ¨™è®ŠåŒ–
- **T+7å¤©**ï¼šè©•ä¼°æ•´é«”æ”¹å–„å¹…åº¦ä¸¦èª¿æ•´ç­–ç•¥

## ğŸ“‹ åŸ·è¡Œå·¥å…·
"""

    for tool in tools_executed:
        report += f"- âœ… {tool}\n"

    report += f"""
---
*ğŸ¤– æœ¬å ±å‘Šç”± AI Agent è‡ªå‹•ç”Ÿæˆ | ç”Ÿæˆæ™‚é–“ï¼š{_get_current_time()}*
"""

    return report


def _get_current_time() -> str:
    """å–å¾—ç•¶å‰æ™‚é–“å­—ä¸²"""
    from datetime import datetime
    return datetime.now().strftime("%Y-%m-%d %H:%M")


# æ¸¬è©¦å‡½æ•¸
def test_report_generation():
    """æ¸¬è©¦å ±å‘Šç”ŸæˆåŠŸèƒ½"""
    test_strategy = {
        "primary_hypothesis": "å»£å‘Šå‡ºåƒ¹éä½",
        "confidence": 0.75,
        "actions": [
            {
                "description": "æé«˜é—œéµè©å‡ºåƒ¹ 20%",
                "impact": "å¢åŠ å»£å‘Šæ›å…‰é‡",
                "risk": "å»£å‘Šæˆæœ¬ä¸Šå‡",
                "kpi": "æ›å…‰é‡æå‡ 30%"
            },
            {
                "description": "å„ªåŒ–ç”¢å“ä¸»åœ–",
                "impact": "æå‡é»æ“Šç‡",
                "risk": "éœ€è¦è¨­è¨ˆæŠ•å…¥",
                "kpi": "CTR æå‡ 15%"
            }
        ]
    }

    test_tools = ["AdsMetrics", "Competitor", "ListingAudit"]

    print("=== æ¸¬è©¦å ±å‘Šç”Ÿæˆ ===")
    report = generate_summary_report(test_strategy, test_tools)
    print(report)


if __name__ == "__main__":
    test_report_generation()